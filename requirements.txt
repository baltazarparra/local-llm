# Core runtime dependencies for ego_proxy
# Python 3.10+ required
#
# Installation Tips for Faster Setup:
# - Use pip with --prefer-binary flag: pip install --prefer-binary -r requirements.txt
# - For even faster installs, use uv: uv pip install -r requirements.txt
# - PyTorch wheels are large (~500MB-2GB). Use pip cache to speed up reinstalls:
#   pip install --cache-dir ~/.cache/pip -r requirements.txt
#
# PyTorch Installation Options:
# - CPU only (faster download, ~200MB): pip install torch --index-url https://download.pytorch.org/whl/cpu
# - CUDA 11.8: pip install torch --index-url https://download.pytorch.org/whl/cu118
# - CUDA 12.1: pip install torch --index-url https://download.pytorch.org/whl/cu121
# - Default (auto-detects): pip install torch (uses PyPI, may be slower)
#
# Note: If you have CUDA installed, PyTorch will automatically use GPU support.
# For CPU-only systems, the default torch package works fine but is larger.

# PyTorch (GPU support)
torch>=2.0.0

# Hugging Face ecosystem
transformers>=4.35.0
accelerate>=0.25.0
tokenizers>=0.15.0

# Configuration
python-dotenv>=1.0.0

# Terminal UI (Enhanced CLI)
rich>=13.0.0
prompt-toolkit>=3.0.0

# Personal Assistant - Semantic Search & Memory
sentence-transformers>=2.2.0  # Semantic embeddings (small, efficient)
numpy>=1.24.0                 # Vector operations
psutil>=5.9.0                 # System and process monitoring

# Google Calendar Integration
google-auth-oauthlib>=1.2.0   # OAuth2 flow for Google Calendar
google-auth-httplib2>=0.2.0   # HTTP transport for Google APIs
google-api-python-client>=2.100.0  # Google Calendar API client
cryptography>=41.0.0          # Token encryption
python-dateutil>=2.8.2        # Natural language date parsing

# Optional: Quantization and optimization
# bitsandbytes>=0.41.0  # Uncomment for 4-bit/8-bit quantization
# safetensors>=0.4.0    # Uncomment for safer model serialization
