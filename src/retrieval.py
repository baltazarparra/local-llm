"""
Intelligent context retrieval engine.

Combines semantic search, entity-based filtering, and temporal ranking
to retrieve the most relevant past conversations.
"""

import logging
from datetime import datetime, timedelta

from .database import AssistantDatabase
from .semantic_search import generate_embedding, embedding_to_bytes, search_conversations

logger = logging.getLogger(__name__)


class ContextRetriever:
    """Retrieve relevant context from conversation history."""

    def __init__(self, database: AssistantDatabase):
        """
        Initialize the context retriever.

        Args:
            database: AssistantDatabase instance
        """
        self.db = database

    def retrieve_relevant_context(
        self,
        query: str,
        top_k: int = 5,
        min_similarity: float = 0.3,
        time_decay: bool = True,
        time_window_days: int | None = None,
        person_filter: str | None = None,
        topic_filter: str | None = None
    ) -> list[Dict]:
        """
        Retrieve relevant context for a query using multiple strategies.

        Args:
            query: The user's query or message
            top_k: Number of results to return
            min_similarity: Minimum semantic similarity threshold
            time_decay: Whether to apply time-based decay to scores
            time_window_days: Only consider conversations within this many days
            person_filter: Only include conversations mentioning this person
            topic_filter: Only include conversations about this topic

        Returns:
            List of relevant conversation dictionaries with metadata
        """
        # Get all embeddings from database
        stored_embeddings = self.db.get_embeddings_for_search()
        
        if not stored_embeddings:
            logger.info("No stored embeddings found")
            return []
        
        # Perform semantic search
        semantic_results = search_conversations(
            query,
            stored_embeddings,
            top_k=top_k * 3,  # Get more candidates for filtering/ranking
            min_similarity=min_similarity
        )
        
        if not semantic_results:
            logger.info("No semantically similar conversations found")
            return []
        
        # Retrieve full conversation details with metadata
        conversations = []
        for conv_id, similarity in semantic_results:
            conv = self.db.get_conversation_with_metadata(conv_id)
            if conv:
                conv['similarity'] = similarity
                conversations.append(conv)

        # Filter out duplicate questions (prevents same question from filling all results)
        conversations = self._filter_duplicate_questions(conversations, query)

        # Apply filters
        conversations = self._apply_filters(
            conversations,
            person_filter=person_filter,
            topic_filter=topic_filter,
            time_window_days=time_window_days
        )

        # Re-rank with combined scoring
        conversations = self._rerank_results(
            conversations,
            apply_time_decay=time_decay,
            query=query
        )
        
        # Return top k results
        return conversations[:top_k]

    def retrieve_by_person(self, person: str, limit: int = 10) -> list[Dict]:
        """
        Retrieve all conversations mentioning a specific person.

        Args:
            person: Person name to search for
            limit: Maximum number of results

        Returns:
            List of conversation dictionaries
        """
        results = self.db.search_by_people(person, limit=limit)
        logger.debug(f"Found {len(results)} conversations mentioning {person}")
        return results

    def retrieve_by_topic(self, topic: str, limit: int = 10) -> list[Dict]:
        """
        Retrieve conversations about a specific topic.

        Args:
            topic: Topic to search for
            limit: Maximum number of results

        Returns:
            List of conversation dictionaries
        """
        results = self.db.search_by_topic(topic, limit=limit)
        logger.debug(f"Found {len(results)} conversations about {topic}")
        return results

    def retrieve_recent(self, days: int = 7, limit: int = 20) -> list[Dict]:
        """
        Retrieve recent conversations within a time window.

        Args:
            days: Number of days to look back
            limit: Maximum number of results

        Returns:
            List of conversation dictionaries
        """
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        conversations = self.db.get_conversations(
            limit=limit,
            start_date=start_date,
            end_date=end_date
        )
        
        logger.debug(f"Found {len(conversations)} conversations in last {days} days")
        return conversations

    def retrieve_timeline(
        self,
        person: str | None = None,
        limit: int = 50
    ) -> list[Dict]:
        """
        Retrieve chronological timeline of conversations.

        Args:
            person: Optional person filter
            limit: Maximum number of conversations

        Returns:
            List of conversations in chronological order
        """
        if person:
            conversations = self.retrieve_by_person(person, limit=limit)
        else:
            conversations = self.db.get_conversations(limit=limit)
        
        # Sort by timestamp (oldest first for timeline)
        conversations.sort(key=lambda x: x.get('timestamp', ''))
        
        return conversations

    def _apply_filters(
        self,
        conversations: list[Dict],
        person_filter: str | None = None,
        topic_filter: str | None = None,
        time_window_days: int | None = None
    ) -> list[Dict]:
        """
        Apply filters to conversation results.

        Args:
            conversations: List of conversations to filter
            person_filter: Filter by person
            topic_filter: Filter by topic
            time_window_days: Filter by time window

        Returns:
            Filtered list of conversations
        """
        filtered = conversations
        
        # Person filter
        if person_filter:
            person_lower = person_filter.lower()
            filtered = [
                conv for conv in filtered
                if any(person_lower in p.lower() for p in (conv.get('people') or []))
            ]

        # Topic filter
        if topic_filter:
            topic_lower = topic_filter.lower()
            filtered = [
                conv for conv in filtered
                if any(topic_lower in t.lower() for t in (conv.get('topics') or []))
            ]
        
        # Time window filter
        if time_window_days:
            cutoff_date = datetime.now() - timedelta(days=time_window_days)
            filtered = [
                conv for conv in filtered
                if self._parse_timestamp(conv.get('timestamp')) >= cutoff_date
            ]
        
        logger.debug(f"Filtered from {len(conversations)} to {len(filtered)} conversations")
        return filtered

    def _filter_duplicate_questions(
        self,
        conversations: list[Dict],
        query: str
    ) -> list[Dict]:
        """
        Filter out duplicate or very similar questions from results.

        When a user asks a question, we don't want to return previous times
        they asked the same question - we want answers/information.

        Args:
            conversations: List of conversations to filter
            query: The current query

        Returns:
            Filtered list with duplicate questions removed
        """
        query_lower = query.lower().strip()

        # Check if the query is a question (starts with what/who/when/where/how/why/is/are/do/does)
        is_question = any(query_lower.startswith(q) for q in [
            'what', 'who', 'when', 'where', 'how', 'why', 'is', 'are', 'do', 'does', 'can', 'will', 'should'
        ])

        if not is_question:
            # Not a question, no need to filter
            return conversations

        filtered = []
        seen_similar_questions = set()

        for conv in conversations:
            content = conv.get('content', '').lower().strip()
            role = conv.get('role', '')

            # Check if this content is very similar to the query (likely same question)
            # Similarity > 0.95 means it's essentially the same question
            if conv.get('similarity', 0) > 0.95 and role == 'user':
                # This is likely the user asking the same/similar question
                # Skip if we've already seen a similar question
                content_short = content[:50]
                if content_short in seen_similar_questions:
                    logger.debug(f"Skipping duplicate question: {content[:100]}")
                    continue
                seen_similar_questions.add(content_short)

                # Keep only ONE instance of similar questions, and de-prioritize it
                conv['is_duplicate_question'] = True

            filtered.append(conv)

        logger.debug(f"Filtered {len(conversations) - len(filtered)} duplicate questions")
        return filtered

    def _rerank_results(
        self,
        conversations: list[Dict],
        apply_time_decay: bool = True,
        query: str | None = None
    ) -> list[Dict]:
        """
        Re-rank results using combined scoring.

        Args:
            conversations: List of conversations with similarity scores
            apply_time_decay: Whether to apply time-based decay

        Returns:
            Re-ranked list of conversations
        """
        for conv in conversations:
            # Base score from semantic similarity
            base_score = conv.get('similarity', 0.5)

            # Time decay: recent conversations get higher scores
            time_score = 1.0
            if apply_time_decay:
                timestamp = self._parse_timestamp(conv.get('timestamp'))
                if timestamp:
                    days_ago = (datetime.now() - timestamp).days
                    # Exponential decay: score halves every 30 days
                    time_score = 0.5 ** (days_ago / 30.0)

            # Role boost: user messages often more informative
            role_score = 1.1 if conv.get('role') == 'user' else 1.0

            # Sentiment boost: emotional content often important
            sentiment = conv.get('sentiment', 'neutral')
            sentiment_score = 1.2 if sentiment in ['negative', 'positive'] else 1.0

            # Duplicate question penalty: strongly de-prioritize repeated questions
            duplicate_penalty = 0.3 if conv.get('is_duplicate_question') else 1.0

            # Content richness boost: longer, more informative messages are better
            content_length = len(conv.get('content', ''))
            content_boost = min(1.5, 1.0 + (content_length / 200))  # Cap at 1.5x

            # Information vs question boost: penalize short questions, boost statements
            content_lower = conv.get('content', '').lower()
            is_short_question = content_length < 100 and any(
                content_lower.startswith(q) for q in ['what', 'who', 'when', 'where', 'how', 'why']
            )
            info_boost = 0.7 if is_short_question else 1.3

            # Combined score
            final_score = base_score * time_score * role_score * sentiment_score * duplicate_penalty * content_boost * info_boost
            conv['final_score'] = final_score
        
        # Sort by final score
        conversations.sort(key=lambda x: x.get('final_score', 0), reverse=True)
        
        return conversations

    def _parse_timestamp(self, timestamp_str: str | None) -> datetime | None:
        """
        Parse timestamp string to datetime object.

        Args:
            timestamp_str: Timestamp string

        Returns:
            Datetime object or None if parsing fails
        """
        if not timestamp_str:
            return None
        
        try:
            # Try parsing ISO format
            return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        except:
            try:
                # Try parsing SQLite format
                return datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
            except:
                logger.warning(f"Could not parse timestamp: {timestamp_str}")
                return None

    def parse_natural_time_filter(self, query: str) -> int | None:
        """
        Parse natural language time references into days.

        Args:
            query: Query text potentially containing time references

        Returns:
            Number of days or None
        """
        query_lower = query.lower()
        
        # Define time patterns
        time_patterns = {
            'today': 1,
            'yesterday': 2,
            'this week': 7,
            'last week': 14,
            'past week': 7,
            'this month': 30,
            'last month': 60,
            'past month': 30,
            'recent': 7,
            'recently': 7
        }
        
        for pattern, days in time_patterns.items():
            if pattern in query_lower:
                return days
        
        # Check for "last N days/weeks"
        import re
        
        days_match = re.search(r'last (\d+) days?', query_lower)
        if days_match:
            return int(days_match.group(1))
        
        weeks_match = re.search(r'last (\d+) weeks?', query_lower)
        if weeks_match:
            return int(weeks_match.group(1)) * 7
        
        return None

    def smart_retrieve(self, query: str, top_k: int = 5) -> list[Dict]:
        """
        Intelligently retrieve context with automatic filter detection.

        Args:
            query: User query
            top_k: Number of results to return

        Returns:
            List of relevant conversations
        """
        # Detect time filters from query
        time_window = self.parse_natural_time_filter(query)
        
        # Detect person mentions (capitalized words)
        import re
        potential_people = re.findall(r'\b[A-Z][a-z]+\b', query)
        person_filter = potential_people[0] if potential_people else None
        
        # Retrieve with detected filters
        return self.retrieve_relevant_context(
            query=query,
            top_k=top_k,
            time_window_days=time_window,
            person_filter=person_filter
        )

